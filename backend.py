# -*- coding: utf-8 -*-
"""backend.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AFcXC9gv0fSDEZ4bGyF6a8X6YAl0fbPn
"""

#!pip install streamlit

# backend.py

import os
import logging
from typing import Tuple, Dict, Optional, Union
import pandas as pd
import joblib
import requests
from pathlib import Path

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configuration (could also use environment variables or a config file)
CONFIG = {
    "MODEL1_URL": "https://raw.githubusercontent.com/bushurumark/EUROPE-MULTI-LEAGUE-FOOTBALL-PREDICTION-APP/main/Models/model1.pkl",
    "MODEL2_URL": "https://raw.githubusercontent.com/bushurumark/EUROPE-MULTI-LEAGUE-FOOTBALL-PREDICTION-APP/main/Models/model2.pkl",
    "DATA1_URL": "https://raw.githubusercontent.com/bushurumark/EUROPE-MULTI-LEAGUE-FOOTBALL-PREDICTION-APP/main/Datasets/football_data1.csv",
    "DATA2_URL": "https://raw.githubusercontent.com/bushurumark/EUROPE-MULTI-LEAGUE-FOOTBALL-PREDICTION-APP/main/Datasets/football_data2.csv",
    "CACHE_DIR": "cache",  # Directory to store downloaded files
}

def ensure_cache_dir() -> Path:
    """Ensure the cache directory exists."""
    cache_dir = Path(CONFIG["CACHE_DIR"])
    cache_dir.mkdir(exist_ok=True)
    return cache_dir

def download_file(url: str, filename: str) -> bool:
    """Download a file from a URL and save it locally."""
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        with open(filename, "wb") as f:
            f.write(response.content)
        logger.info(f"Downloaded {filename} from {url}")
        return True
    except requests.RequestException as e:
        logger.error(f"Failed to download {url}: {e}")
        return False

def download_file_if_needed(url: str, filename: str) -> bool:
    """Download a file if it doesn't already exist."""
    cache_dir = ensure_cache_dir()
    filepath = cache_dir / filename
    if not filepath.exists():
        return download_file(url, filepath)
    return True

def load_model(filename: str):
    """Load a model from a file."""
    try:
        model = joblib.load(filename)
        logger.info(f"Loaded model from {filename}")
        return model
    except Exception as e:
        logger.error(f"Failed to load model from {filename}: {e}")
        raise

def download_and_load_models() -> Tuple:
    """Download and load both models."""
    cache_dir = ensure_cache_dir()
    model1_path = cache_dir / "model1.pkl"
    model2_path = cache_dir / "model2.pkl"
    
    if not download_file_if_needed(CONFIG["MODEL1_URL"], "model1.pkl"):
        raise FileNotFoundError(f"Failed to download model1.pkl")
    if not download_file_if_needed(CONFIG["MODEL2_URL"], "model2.pkl"):
        raise FileNotFoundError(f"Failed to download model2.pkl")
    
    model1 = load_model(model1_path)
    model2 = load_model(model2_path)
    return model1, model2

def load_data() -> Tuple[pd.DataFrame, pd.DataFrame]:
    """Download and load both datasets."""
    cache_dir = ensure_cache_dir()
    data1_path = cache_dir / "football_data1.csv"
    data2_path = cache_dir / "football_data2.csv"
    
    if not download_file_if_needed(CONFIG["DATA1_URL"], "football_data1.csv"):
        raise FileNotFoundError(f"Failed to download football_data1.csv")
    if not download_file_if_needed(CONFIG["DATA2_URL"], "football_data2.csv"):
        raise FileNotFoundError(f"Failed to download football_data2.csv")
    
    data1 = pd.read_csv(data1_path)
    data2 = pd.read_csv(data2_path)
    logger.info("Loaded datasets successfully")
    return data1, data2

def compute_mean_for_teams_v1(home: str, away: str, data: pd.DataFrame, model) -> Optional[pd.DataFrame]:
    """Compute mean features for teams (version 1)."""
    try:
        h2h = data[(data['HomeTeam'] == home) & (data['AwayTeam'] == away)]
        if h2h.empty:
            logger.warning(f"No historical data found for {home} vs {away}")
            return None
        
        h2h = h2h.drop(columns=['FTR', 'Date', 'HomeTeam', 'AwayTeam'], errors='ignore')
        h2h['HTR'] = h2h['HTR'].replace({'H': 1, 'D': 2, 'A': 3})
        mean = h2h.mean(numeric_only=True)
        
        if 'HTR' in mean:
            if 0 <= mean['HTR'] <= 1.4:
                mean['HTR'] = 'H'
            elif 1.5 <= mean['HTR'] <= 2.4:
                mean['HTR'] = 'D'
            elif 2.5 <= mean['HTR'] <= 3.4:
                mean['HTR'] = 'A'
        
        input_df = pd.DataFrame([mean])
        for f in model.feature_names_in_:
            if f not in input_df:
                input_df[f] = 0
        return input_df[model.feature_names_in_]
    except Exception as e:
        logger.error(f"Error in compute_mean_for_teams_v1: {e}")
        return None

def compute_mean_for_teams_v2(home: str, away: str, data: pd.DataFrame, model) -> Optional[pd.DataFrame]:
    """Compute mean features for teams (version 2)."""
    try:
        h2h = data[(data['Home'] == home) & (data['Away'] == away)]
        if h2h.empty:
            logger.warning(f"No historical data found for {home} vs {away}")
            return None
        
        h2h = h2h.drop(columns=["Res", "Date", "Country", "League", "Season", "Time"], errors='ignore')
        mean = h2h.mean(numeric_only=True)
        input_df = pd.DataFrame([mean])
        
        for f in model.feature_names_in_:
            if f not in input_df:
                input_df[f] = 0
        return input_df[model.feature_names_in_]
    except Exception as e:
        logger.error(f"Error in compute_mean_for_teams_v2: {e}")
        return None

def calculate_probabilities_v1(home: str, away: str, data: pd.DataFrame) -> Optional[Dict[str, float]]:
    """Calculate win probabilities (version 1)."""
    try:
        h2h = data[(data['HomeTeam'] == home) & (data['AwayTeam'] == away)]
        if h2h.empty:
            logger.warning(f"No historical data found for {home} vs {away}")
            return None
        
        total = len(h2h)
        return {
            "Home Team Win": (h2h['FTR'] == 'H').sum() / total * 100,
            "Draw": (h2h['FTR'] == 'D').sum() / total * 100,
            "Away Team Win": (h2h['FTR'] == 'A').sum() / total * 100,
        }
    except Exception as e:
        logger.error(f"Error in calculate_probabilities_v1: {e}")
        return None

def calculate_probabilities_v2(home: str, away: str, data: pd.DataFrame) -> Optional[Dict[str, float]]:
    """Calculate win probabilities (version 2)."""
    try:
        h2h = data[(data['Home'] == home) & (data['Away'] == away)]
        if h2h.empty:
            logger.warning(f"No historical data found for {home} vs {away}")
            return None
        
        total = len(h2h)
        return {
            "Home Team Win": (h2h['Res'] == 'H').sum() / total * 100,
            "Draw": (h2h['Res'] == 'D').sum() / total * 100,
            "Away Team Win": (h2h['Res'] == 'A').sum() / total * 100,
        }
    except Exception as e:
        logger.error(f"Error in calculate_probabilities_v2: {e}")
        return None

def determine_final_prediction(pred: float, probs: Dict[str, float]) -> str:
    """Determine the final prediction based on model output and probabilities."""
    try:
        if 0.5 <= pred <= 1.4:
            model_outcome = "Home Team Win"
        elif 1.5 <= pred <= 2.4:
            model_outcome = "Draw"
        elif 2.5 <= pred <= 3.4:
            model_outcome = "Away Team Win"
        else:
            return "❗ Invalid prediction"

        highest_prob = max(probs, key=probs.get)
        if model_outcome == highest_prob:
            return model_outcome

        tied = [k for k, v in probs.items() if v == probs[highest_prob]]
        if len(tied) > 1:
            return f"{model_outcome} or {tied[1]}" if tied[1] != model_outcome else f"{tied[0]} or {model_outcome}"
        return f"{model_outcome} or {highest_prob}"
    except Exception as e:
        logger.error(f"Error in determine_final_prediction: {e}")
        return "❗ Error in prediction"
